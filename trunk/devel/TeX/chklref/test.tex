%% -*- ispell-local-dictionary: "francais"; -*-

\documentclass[10pt]{beamer}
\usepackage{pgf,pgfpages,color}
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{stmaryrd}
%% fourier package is too verbose
\makeatletter
\let\@font@warningori\@font@warning
\def\@font@warning#1{}
\usepackage{fourier}
\let\@font@warning\@font@warningori
\makeatother 
\usepackage{enumerate}
\usepackage{figlatex}% to include .fig files
\usepackage{subfigure}%
\usepackage{appendixnumberbeamer}

\mode
<handout>
\pgfpagesuselayout{4 on 1}[a4paper,border shrink=5mm,landscape]
\hypersetup{colorlinks=false,%
  bookmarks=false}

\mode
<beamer>
\hypersetup{colorlinks=true,linkcolor=blue,%
  bookmarks=false}
\mode
<all>

\graphicspath{{double_parisian_fig/}
  {fig/}}
\usetheme{JLTree}
\usefonttheme{serif}



\makeatletter

%% -------------------------------------------------------------%%
%% Math Cal 
\def\ca{{\mathcal A}}
\def\cb{{\mathcal B}}
\def\cc{{\mathcal C}}
\def\cd{{\mathcal D}}
\def\ce{{\mathcal E}}
\def\cf{{\mathcal F}}
\def\cg{{\mathcal G}}
\def\ch{{\mathcal H}}
\def\ci{{\mathcal I}}
\def\cj{{\mathcal J}}
\def\ck{{\mathcal K}}
\def\K{{\mathcal K}}
\def\cl{{\mathcal L}}
\def\cn{{\mathcal N}}
\def\cm{{\mathcal M}}
\def\co{{\mathcal O}}
\def\cp{{\mathcal P}}
\def\cq{{\mathcal Q}}
\def\cs{{\mathcal S}}
\def\cu{{\mathcal U}}
\def\ct{{\mathcal T}}
\def\cw{{\mathcal W}}
\def\cx{{\mathcal X}}
\def\cz{{\mathcal Z}}

\def\C{{\mathbb C}}
\def\D{{\mathbb D}}
\def\E{{\mathbb E}}
\def\F{{\mathbb F}}
\def\L{{\mathbb L}}
\def\N{{\mathbb N}}
\def\P{{\mathbb P}}
\def\Q{{\mathbb Q}}
\def\R{{\mathbb R}}
\def\Z{{\mathbb Z}}
%% -------------------------------------------------------------%%


%% -------------------------------------------------------------%%
%% Operators
\def\overbar{\overline}
\def\rP{{\rm P}}
\def\rQ{{\rm Q}}
\def\rpartial{{\rm d}}
\def\s{\star}
\def\w{\widehat}
\def\la{\lambda}
\def\te{\theta}
\def\ts{\tau^\s}
\def\defeq{\stackrel{\Delta}{=}}
\def\ind#1{{\bf 1}_{\{#1\}}}
\def\lind#1{{\bf 1}_{\left\{#1\right\}}}
\def\indd#1{{\bf 1}_{#1}}
\def\id{{\mathcal I}}
\def\abs#1{\left|#1\right|}
\def\supp{{\rm supp}\;}
\def\Det{{\rm det}\;}
\def\Card{{\rm Card}\;}
\def\cov{\operatorname{Cov}}
\def\Cov{{\rm Cov}\;}
\def\Var{\mathop{\rm Var}\nolimits}
\def\var{\text{Var}}
\def\norm#1{\mathop{\left\| #1 \right\|}\nolimits}
\def\val#1{\mathop{\left| #1 \right|}\nolimits}
\def\inv#1{\mathop{\frac{1}{ #1}}\nolimits}
\def\expp#1{\mathop {\mathrm{e}^{ #1}}}
\def\interior#1{\mathop {\mathrm{int}(#1)}}
\def\simm#1{\underset{#1}{\sim}}
\def\sgn{\operatorname{sgn}}
\def\real#1{\mathop {\mathcal{R}\mathrm{e}\left( #1\right)}}
\def\imag#1{\mathop {\mathcal{I}\mathrm{m}\left( #1\right)}}
\def\Rightarrowfill@{\arrowfill@\Relbar\Relbar\Longrightarrow}
\newcommand{\Xrightarrow}[2][]{\ext@arrow 0359\Rightarrowfill@{#1}{#2}}
\def\then{$\Longrightarrow$}

\makeatletter
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\makeatother

%% -------------------------------------------------------------%%

%% -------------------------------------------------------------%%


%% ------------------------------------------------------------------------- %%
%% Hypotheses

\definecolor{rose}{rgb}{0.92,0.10,0.12}
\definecolor{blue}{rgb}{0,0,1}

\def\blue{\color{blue}}
\newcounter{hypo}
\newcommand*{\dohypo}{\textcolor{blue}{(${\mathcal H}$\thehypo)}}
\newenvironment{hypo}[1][]{%
  \refstepcounter{hypo}
  \dohypo\ #1}%
{\par}


\def\subhypo{\enumerate[(i)]}
\def\endsubhypo{\endenumerate}

\def\hypref#1{\hyperlink{hyp_#1}{(${\mathcal H}$\ref{hyp_#1})}}
\def\hypreff#1#2{\hyperlink{hyp_#2}{(${\mathcal H}$\ref{hyp_#1}-{\it \ref{hyp_#2})}}}

\newenvironment{preuve}{{\it Preuve :~}}%
{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill%
  \hbox{$\blacktriangle$}}


\def\vpar{\vspace*{11pt}}

%% ------------------------------------------------------------------------- %%
%% Beamer template

\setbeamertemplate{frametitle continuation}[from second]
\setbeamertemplate{theorem begin}
{%\setbeamercolor{block body}{bg=red}
  \begin{\inserttheoremblockenv}
    {%
      \inserttheoremheadfont
      \inserttheoremname
      \inserttheoremnumber
      \ifx\inserttheoremaddition\empty\else\ (\inserttheoremaddition)\fi%
    }%
  }
  \setbeamertemplate{theorem end}
  {\end{\inserttheoremblockenv}}

\setbeamercovered{transparent}
\setbeamertemplate{bibliography item}[triangle]


\makeatletter
\setbeamertemplate{enumerate items}[ball]
\newcounter{algocount}
\setcounter{algocount}{0}
\newenvironment{algo}[1][]{
  \refstepcounter{algocount}
  
  Algorithme \thealgocount\ \@ifnotempty{#1}{(#1)}. \fontshape{it}\selectfont}
{}
\makeatother

\newtheorem{thm}{Théorème}
\newtheorem{prop}{Proposition}
\newtheorem*{cor}{Corollaire}
\newtheorem{lem}{Lemme}
\newtheorem*{Res}{Fact}


\definecolor{vert}{rgb}{0.12,0.90,0.}
\newenvironment{res}[1][]{%
  \setbeamercolor{block title}{fg=black,bg=green!40!black}
  \setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!20!bg}
  \begin{Res}[#1]}{
  \end{Res}
  \setbeamercolor{block title}{use=structure,fg=structure.fg,bg=structure.fg!20!bg}
  \setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!50!bg}
}
\newenvironment{remark}{{\it Remark.} }{}


%% ------------------------------------------------------------------------- %%


\title[MC Américain]{Méthodes de Monte Carlo pour les options Américaines}

\author[J. Lelong]{Jérôme Lelong}
\institute[(MathFi -- INRIA)]{\url{http://cermics.enpc.fr/~lelong}}
\date{Vendredi 30 novembre 2007}

\mode
<beamer>
%% including creates huge ps files
\logo{\includegraphics[height=0.7cm]{logo-inria.pdf}}

\mode
<all>

\AtBeginDocument{\def\figurename{{\scshape Fig.}}}
\AtBeginDocument{\def\tablename{{\scshape Tab.}}} 


\begin{document}
\frame{\titlepage}

\begin{frame}
  \frametitle{Plan}
  \tableofcontents
\end{frame}


\section{Introduction}
\subsection{Le modèle de marché}

%% ------------------------------------------------------------------------- %%
\begin{frame}[allowframebreaks]
  \frametitle{Le modèle de marché}

  On se restreint au modèle de Black Scholes $d-$dimensionnel. Soit
  $S_{t}:=\left(S_{t}^{1},\ldots,S_{t}^{d}\right)$ le vecteur des cours des
  actifs.
  
  \begin{itemize}
  \item $\left(B_{t}\right)_{t\ge 0}$ est un M.B. $d$--dimensionnel,
  \item $r>0$ le taux d'intérêt sans risque (supposé constant),
  \item $\delta_{1},\ldots,\delta_{d}>0$ les taux de dividende des actifs
    $S_{t}^{1},\ldots,S_{t}^{d}$, supposés déterministes et constants,
  \item $\mu_{1},\ldots,\mu_{d}>0$ les rendements des actifs
    $S_{t}^{1},\ldots,S_{t}^{d}$, supposés déterministes et constants,
  \item $\Sigma$ une matrice définie positive de taille $d\times d$ et 
    $\sigma$ sa racine carrée,
  \item $S_{0}:=\left(S_{0}^{1},\ldots,S_{0}^{d}\right)$ le vecteur des valeurs
    initiales des actifs (supposées déterministes).
  \end{itemize}

  La dynamique du court de l'actif $i$ est donnée par
  \begin{equation*}
    \label{eq:poo}
    dS_{t}^{i}=S_{t}^{i}\left(\mu_{i}\,dt +
      \sum_{1\le j\le i}\sigma_{i,j}d B_t^j\right).
  \end{equation*}
  De manière équivalente
  \begin{equation*}
    S_{t}^{i}=S_{0}^{i}\exp\left(-t\left(\frac{1}{2}\sum_{1\le j\le
          i}\sigma_{i,j}^{2}-r+\delta_{i}\right) +
      \sum_{1\le j\le i}\sigma_{i,j}W_{t}^{j}\right),
  \end{equation*}
  sous la probabilité risque neutre $\P$, avec $W$ un M.B. sous $\P$.
\end{frame}
%% ------------------------------------------------------------------------- %%

\subsection{Options Américaines}
%% ------------------------------------------------------------------------- %%
\begin{frame}[allowframebreaks]
  \frametitle{Options Américaines}

  On considère une option américaine de maturité $T$ et de payoff $\phi$. Son
  prix à l'instant $0$ est donné par
  \begin{equation}    \label{eq:prix_amer}
    \sup_{\tau \in \tilde \ct_{0,T}} \E(\expp{-r\tau} \phi(S_\tau)),
  \end{equation}
  où $\tilde \ct_{0,T}$ est l'ensemble des temps d'arrêt à valeurs dans $[0,
  T]$.
  En posant
  \begin{equation*}
    \tilde P(t, x) = \sup_{\tau \in \tilde \ct_{0,T-t}} \E(\expp{-r\tau}
    \phi(x S_{\tau})),
  \end{equation*}
  le prix à la date $t$ est $ \tilde P(t, S_t)$.
\end{frame}
%% ------------------------------------------------------------------------- %%

%% ------------------------------------------------------------------------- %%
\begin{frame}[allowframebreaks]
  \frametitle{Options Bermudéennes}
  En pratique, on approche le prix par celui d'une option Bermudéenne (nombre fini de
  dates d'exercices $0=t_0 < t_1 < \dots < t_N=T$)
  \begin{equation}
    \label{eq:prix_bermude}
    P(t_0, S_{t_0}) = \sup_{\tau \in \ct_{0,N}} \E(\expp{-r\tau} \phi(S_\tau)),
  \end{equation}
  où $\ct_{0,N}$ est l'ensemble des temps d'arrêt à valeurs dans $\{t_0, \dots, t_N\}$. 

  {\bf Programmation dynamique.} Le prix $P(t_0, S_{t_0})$ est solution du
  problème
  \begin{equation}
    \label{eq:prog_dyn_prix}
    \begin{cases}
      P(t_N, S_{t_N}) & = \phi(S_{t_N})\\
      P(t_{j-1}, S_{t_{j-1}}) &= \max(\phi(S_{t_{j-1}}), \; \E (\expp{-r(t_j - t_{j-1})}
      P(t_j, S_{t_j}) | S_{t_{j-1}})),
      \quad 1\le j \le N.
    \end{cases}
  \end{equation}
  On peut montrer que $\tau^\s := \min\{t_n \, : \, \phi(S_{t_n}) = P(t_n, S_{t_n})\}$
  atteint l'optimum dans~\eqref{eq:prix_bermude}
  \begin{equation*}
    P(t_0, S_{t_0}) = \E(\expp{-r\tau^\s} \phi(S_{\tau^\s}))
  \end{equation*}
  et c'est le plus petit tel t.a..
  
  De manière équivalente en posant $U_n = \expp{-r t_n} P(t_n, S_{t_n})$
  \begin{equation}
    \label{eq:prog_dyn}
    \begin{cases}
      U_N & = \expp{-r t_N} \phi(S_{t_N})\\
      U_n &= \max(\expp{-r t_n} \phi(S_{t_n}), \; \E (U_{n+1} | S_{t_{n}})),
      \quad 0\le n \le N-1. 
    \end{cases}
  \end{equation}
  
  \begin{equation*}
    U_n = \sup_{\tau \in \ct_{n,N}} \E (\expp{-r\tau}
    \phi(S_\tau) | \cf_{t_{n}} ).
  \end{equation*}
  $\tau^\s_n := \min\{t_i \, : \, i \geq n, \quad \phi(S_{t_i}) \expp{-r t_i} =
  U_i\}$ est le t.a. optimal après $t_n$.
  \begin{equation*}
    U_n = \E (\expp{-r\tau^\s_n}
    \phi(S_{\tau^\s_n}) | S_{t_{n}} )
  \end{equation*}
\end{frame}
%% ------------------------------------------------------------------------- %%

\section{Les algorithmes}

\begin{frame}
  \frametitle{Plan}
  \tableofcontents[currentsection]
\end{frame}


%% ------------------------------------------------------------------------- %%
\begin{frame}
  \frametitle{Les algorithmes}

  3 types d'algorithmes : 
  \begin{enumerate}[1]
  \item Programmation dynamique
    \begin{enumerate}[(a)]
    \item approximation de l'espérance conditionnelle $\E (\expp{-r(t_j - t_{j-1})}
      P(t_j, S_{t_j}) | S_{t_{j-1}})$.
    \item $P(t_0, S_{t_0})$ donne le prix à l'instant $0$.
    \end{enumerate}
  \item Temps d'arrêt optimal $\tau^\s$.
    \begin{enumerate}[(a)]
    \item approximation du temps d'arrêt optimal $\tau^\s$
    \item calcul de $\E(\expp{-r \tau^\s} \phi(S_{\tau^\s}))$ par méthode de
      Monte Carlo.
    \end{enumerate}
  \item Stratégie sous-optimale
    \begin{enumerate}[(a)]
    \item  On cherche un temps d'arrêt sous-optimal puis calcul de l'espérance
      par Monte Carlo.
    \end{enumerate}
  \end{enumerate}
\end{frame}
%% ------------------------------------------------------------------------- %%

\subsection{Algorithme de Longstaff Schwartz}
\begin{frame}
  \frametitle{Plan}
  \tableofcontents[currentsection, currentsubsection]
\end{frame}

%% ------------------------------------------------------------------------- %%
\begin{frame}
  \frametitle{Algorithme de Longstaff Schwartz}

  {\bf Principe~:} Tirer $M$ trajectoires du modèle de Black Scholes
  $(\omega_i)_{1 \leq i \leq M}$. Sur
  chacune d'elle, approcher le t.a. $\ts$ par une v.a. $\tilde \tau$ et
  calculer  $P(t_0, S_{t_0})$ par Monte Carlo
  \begin{equation}
    \label{eq:1}
    P_0^M = \inv{M} \sum_{i=1}^M \expp{-r\tilde \tau(\omega_i)} \phi(S_{\tilde
      \tau (\omega_i)})
  \end{equation}

  Construction de $\tilde \tau$ :
  \begin{itemize}
  \item équation de programmation dynamique pour déterminer $\ts$ récursivement,
  \item approximation proposée par Longstaff et Schwartz.
  \end{itemize}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{Programmation dynamique pour $\ts$ I}
  
  On cherche à construire une suite $(\ts_i)_{0 \leq i \leq N}$ de manière
  backward t.q. $\ts = \ts_0$.

  Soit $\ts_N = T$ et
  \begin{equation*}
    \ts_i := \min\{t_j \, : \, j \geq i, \quad\phi(S_{t_i}) \expp{-r t_i} = U_i\}.
  \end{equation*}

  \begin{equation*}
    \begin{cases}
      \ts_N & = T \\
      \ts_i & = i \; \ind{\phi(S_{t_i}) \expp{-r t_i} \geq U_i} +  \ts_{i+1}
      \ind{\phi(S_{t_i}) \expp{-r t_i} < U_i} \quad 0 \leq i \leq N-1. 
    \end{cases}
  \end{equation*}
  On peut se débarrasser de $U_i$ grâce à l'équivalence
  \begin{equation*}
    \phi(S_{t_i}) \expp{-r t_i} < U_i \quad \Longleftrightarrow \quad  
    \phi(S_{t_i}) \expp{-r t_i} < \E (\expp{-r \ts_{i+1}}
    \phi(S_{\ts_{i+1}}) | S_{t_{i}})
  \end{equation*}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{Programmation dynamique pour $\ts$ II}
  On pose
  \begin{equation}
    \label{eq:set_A}
    A_i := \left\{ \phi(S_{t_i}) \expp{-r t_i} \geq \E (\expp{-r \ts_{i+1} }
      \phi(S_{\ts_{i+1}}) | S_{t_{i}}) \right\}.
  \end{equation}

  \begin{equation}
    \label{eq:prog_dyn_tau}
    \begin{cases}
      \ts_N & = T \\
      \ts_i & = i \; \ind{A_i} +  \ts_{i+1}
      \ind{A_i^c} \quad 0 \leq i \leq N-1. 
    \end{cases}
  \end{equation}
  Il n'y a plus de dépendance en $U$, seulement en $(\ts_j, j \leq N)$.

  {\bf Principale difficulté~:} approcher $\psi_i(S_{t_i}) = \E
  (\expp{-r \ts_{i+1}} \phi(S_{\ts_{i+1}}) | S_{t_{i}})$.

  {\bf Idée~:} Minimiser $\E( \{\expp{-r \ts_{i+1}} \phi(S_{\ts_{i+1}}) -
  \psi_i(S_{t_i})\}^2)$ pour $\psi_i$ dans un ensemble de fonctions bien choisies.
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{LS : étape de régression}

  \begin{itemize}
  \item   On pose $f(t, x) = \expp{-r t} \phi(x)$. On cherche à minimiser
    $\E( \{ f(\ts_{i+1}, S_{\ts_{i+1}}) - \psi_i(S_{t_i})\}^2)$. 
    
  \item Soit $(g_l, l \geq 1)$ une base de fonctions $R^d \longrightarrow R$
    t.q. $\E(g(S_{t_i}) g(S_{t_i})^T) < \infty$ pour tout $i$. 
  \item $\psi_i = \sum_{l \geq 1} \alpha^i_l g_l$.
  \item Le calcul de $\E(f(\ts_{i+1}, S_{\ts_{i+1}})| S_{t_i})$ est remplacé par
    la détermination de $\alpha^i$ qui minimise
    \begin{equation*}
      \E\left( \left[ f(\ts_{i+1}, S_{\ts_{i+1}}) -
          (\alpha^i \cdot g)(S_{t_i}) \right]^2\right).
    \end{equation*}
  \end{itemize}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{LS: algorithme d'arrêt optimal}

  \begin{enumerate}[1.]
  \item Initialisation : $\ts_N = t_N$. Pour $i=N-1 \dots 0$,
  \item détermination de $\alpha^i = (\alpha^i_l, l \geq 1)$ qui minimise
    \begin{equation}
      \label{eq:ls_reg}
      \E\left( \left[ f(\ts_{i+1}, S_{\ts_{i+1}}) -
          (\alpha^i \cdot g)(S_{t_i}) \right]^2\right),
    \end{equation}
  \item on définit
    \begin{equation*}
      \ts_i  = i \; \ind{f(t_i, S_{t_i}^{(m)}) \geq (\alpha^i \cdot
        g)(S_{t_i})} +  \ts_{i+1} \ind{f(t_i, S_{t_i}) < (\alpha^i
        \cdot g)(S_{t_i})}.
    \end{equation*}
  \end{enumerate}

  {\bf Remarque : }
  \begin{itemize}
  \item $\alpha^i$ est un vecteur de taille infinie,
  \item l'espérance n'est pas connue explicitement,
  \item besoin de 2 approximations :
    \begin{itemize}
    \item tronquer $\alpha^i$: revient à prendre une famille libre de $\L^2$
      plutôt qu'une base,
    \item calculer l'espérance dans~\eqref{eq:ls_reg} grâce à une méthode de
      Monte Carlo.
    \end{itemize}
  \end{itemize}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{LS: étape de troncature}

  \begin{enumerate}[1.]
  \item initialisation : $\hat\tau_N = t_N$. Pour $i=N-1 \dots 0$,
  \item détermination de  $\hat \alpha^{i,k} = (\hat \alpha^{i,k}_l, 1 \leq l
    \leq k)$ qui minimise 
    \begin{equation*}
      \E\left( \left[ f(\ts_{i+1}, S_{\ts_{i+1}}) - (\hat \alpha^{i,k} \cdot
          g)(S_{t_i}) \right]^2\right) 
    \end{equation*}
    avec $\hat \alpha^{i,k} \cdot g = \sum_{l=1}^k \hat \alpha^{i,k}_l g_l$,
  \item on définit
    \begin{equation*}
      \hat \tau_i  = i \; \ind{f(t_i, S_{t_i}) \geq (\hat \alpha^{i,k}
        \cdot g)(S_{t_i})} +  \hat \tau_{i+1} \ind{f(t_i, S_{t_i}) <
        (\hat \alpha^{i,k} \cdot g)(S_{t_i})}.
    \end{equation*}
  \end{enumerate}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{LS: étape de Monte Carlo}

  \begin{enumerate}[1.]
  \item $S^{(m)}$ $M$ copies indépendantes de $(S_{t_1}, \dots, S_{t_N})$.


  \item Initialisation : $\tau_N^M = t_N$.
  \item Détermination de  $\alpha^i = (\alpha^{i}_l, 1 \leq l
    \leq k)$ qui minimise 
    \begin{equation*}
      \inv{M} \sum_{m=1}^M  \left( f\left(\tau_{i+1}^{(m)},
          S_{\tau_{i+1}^{(m)}}^{(m)}\right) - ( 
        \alpha^{i} \cdot g)(S_{t_i}^{(m)}) \right)^2.
    \end{equation*}
  \item On définit pour chaque $m$
    \begin{equation*}
      \tau_i^{(m)}  = i \; \ind{f(t_i, S_{t_i}^{(m)}) \geq (\hat \alpha^{i}
        \cdot g)(S_{t_i}^{(m)})} +  \tau_{i+1}^{(m)} \ind{f(t_i, S_{t_i}^{(m)}) <
        (\hat \alpha^{i} \cdot g)(S_{t_i}^{(m)})}.
    \end{equation*}
  \item Prix à l'instant $0$ donné par
    \begin{equation*}
      \inv{M} \sum_{m=1}^M f\left(\tau_{0}^{(m)},S_{\tau_{0}^{(m)}}^{(m)}\right).
    \end{equation*}
  \end{enumerate}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{LS: quelques remarques}

  \begin{itemize}
  \item A l'instant $t_j$, si $\phi(S_{t_j}) = 0$, on n'exerce pas l'option. Pas
    besoin de calculer $\E(f(\ts_{i+1}, S_{\ts_{i+1}}) | S_{t_i})$ sur
    l'ensemble $\{\phi(S_{t_j}) = 0 \}$.
  \item On peut ajouter le payoff à la base au moins pour les temps proches de
    la maturité. La base peut changer au cours du temps.
  \item Il peut être intéressant de travailler avec $\tilde S_{t_j} =
    \Sigma_j^{-1} (S_{t_j} - m_j)$ avec $m_j$ et $\Sigma_j$ la moyenne et la
    dispersion du modèle de Black Scholes à l'instant $t_j$.
  \item Besoin de garder toutes les trajectoires pour calculer
    \begin{equation*}
      \inv{M} \sum_{m=1}^M f\left(\tau_{0}^{(m)},S_{\tau_{0}^{(m)}}^{(m)}\right).
    \end{equation*}
    taille : $M \times N \times d$.
  \end{itemize}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{LS: amélioration}

  \begin{equation*}
    \begin{cases}
      P(t_N, S_{t_N}) & = \phi(S_{t_N})\\
      P(t_{j-1}, S_{t_{j-1}}) &= \max(\phi(S_{t_{j-1}}), \; \E (\expp{-r(t_j - t_{j-1})}
      P(t_j, S_{t_j}) | S_{t_{j-1}})),
      \quad 1\le j \le N.
    \end{cases}
  \end{equation*}

  \begin{enumerate}[1.]
  \item on simule M tirages de $S_{t_N}^{(m)}$
  \item On pose $j=N-1$ et $f(t_{j+1}, S_{t_{j+1}}^{(m)}) = \expp{-r \Delta T}
    \phi(S_{t_{j+1}}^{(m)})$ pour $m=1 \dots M$.
  \item \label{ls_loop} on ne garde que les $M_j$ trajectoires à la monnaie
  \item on calcule $\alpha^j$ qui minimise
    \begin{equation*}
      \inv{M_j} \sum_{m=1}^{M_j}  \left( f(t_{j+1}, S_{t_{j+1}}^{(m)})-
        (\alpha^{j} \cdot g)(S_{t_j}^{(m)}) \right)^2. 
    \end{equation*}
  \item on pose $P(t_j, S_{t_j}^{(m)}) = \max(\phi(S_{t_{j}}^{(m)}), (\alpha^j
    \cdot g)(S_{t_{j}}^{(m)}))$ pour $m=1 \dots M$.
  \item on pose $f(t_{j}, S_{t_{j}}^{(m)}) = \expp{-r \Delta T} P(t_j,
    S_{t_j}^{(m)})$.
  \item si $j>1$, on pose $j=j-1$ et retourne à \ref{ls_loop}. \\
    si $j=1$, $P(t_0,
    S_{t_0}) = \max\left(\phi(S_{t_{0}}), \inv{M} \sum_{m=1}^M f(t_{1},
      S_{t_{1}}^{(m)})\right)$. 
  \end{enumerate}

  Cette fois, pas besoin de conserver toutes les trajectoires. \\
  on utilise la simulation backward de $S_{t_j}$ sachant  $S_{t_{j+1}}$. \\
  taille : $M\times d$.
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{Simulation rétrograde du Brownien}

  On cherche $S_{t_j}$ connaissant $S_{t_{j+1}}$ (et aussi $S_0$). On utilise la
  simulation Simulation rétrograde du Brownien.
  Sachant $B_{t_{j+1}} = b$, la loi de $B_{t_j}$ est une loi gaussienne
  \begin{equation*}
    \cn\left( b \frac{t_{j}}{t_{j+1}}, \frac{t_{j}}{t_{j+1}} (t_{j+1} - t_j) \right).
  \end{equation*}
  \begin{preuve}
    Il suffit de considérer la v.a.
    \begin{equation*}
      Y_j = B_{t_j} - \beta B_{t_{j+1}} 
    \end{equation*}
    et de chercher $\beta$ pour que $Y_j \independent B_{t_{j+1}}$. \then\  $\beta
    = \frac{t_{j}}{t_{j+1}}$. $Y_j$ est une gaussienne centrée indépendante de
    $B_{t_{j+1}}$, reste à calculer sa variance.
  \end{preuve}
\end{frame}
%% ------------------------------------------------------------------------- %%


\begin{frame}
  \frametitle{Résolution du problème des moindres carrés}

  On cherche à trouver $\alpha$, vecteur de $\R^k$, qui minimise   
  $\sum_{i=1}^M (Z_i - (\alpha \cdot g)(X_i))^2.$
  
  De manière équivalente en dérivant par rapport à $\alpha_j$
  \begin{eqnarray*}
    \sum_{i=1}^M \left(Z_i - (\sum_{l=0}^k \alpha_l  g_l)(X_i)\right)  g_j(X_i) & =& 0,
    \\
    \sum_{l=0}^k  \left(\sum_{i=1}^M  g_j(X_i) g_l(X_i)\right) \alpha_l & = &
    \sum_{i=1}^M Z_i g_j(X_i).
  \end{eqnarray*}
  On pose $D^{(M)}_{j,l} = \sum_{i=1}^M  g_j(X_i) g_l(X_i)$,
  \begin{equation*}
    \sum_{i=1}^M Z_i g(X_i) = D^{(M)} \alpha.
  \end{equation*}
  $D$ est symétrique et en pratique si la base n'est pas trop grande, elle est
  définie positive. On calcule $D^{-1}$ grâce à l'algorithme de Cholesky.
\end{frame}
%% ------------------------------------------------------------------------- %%
%% ------------------------------------------------------------------- FIN - %%

\subsection{Algorithme de Tsitsiklis VanRoy}
\begin{frame}
  \frametitle{Plan}
  \tableofcontents[currentsection, currentsubsection]
\end{frame}

\begin{frame}
  \frametitle{Algorithme de  Tsitsiklis VanRoy}
  Programmation dynamique : 
  \begin{equation*}
    \begin{cases}
      P(t_N, S_{t_N}) & = \phi(S_{t_N})\\
      P(t_{j-1}, S_{t_{j-1}}) &= \max(\phi(S_{t_{j-1}}), \; \E (\expp{-r(t_j - t_{j-1})}
      P(t_j, S_{t_j}) | S_{t_{j-1}})),
      \quad 1\le j \le N.
    \end{cases}
  \end{equation*}
  
  On pose
  \begin{equation*}
    Q_j := \E (\expp{-r(t_{j+1} - t_{j})}
    P(t_{j+1}, S_{t_{j+1}}) | S_{t_{j}}).
  \end{equation*}

  \begin{equation*}
    \begin{cases}
      Q_{N-1}  & = \E (\expp{-r(t_{N} - t_{N-1})}
      \phi(S_{t_{N}}) | S_{t_{N-1}}), \\
      Q_{j} &= \E\left( \expp{-r(t_{j+1} - t_{j})} \max(\phi(S_{t_{j+1}}), \;
        Q_{j+1}) | S_{t_{j}}) \right)
      , \quad 0 \le j \le N-2.
    \end{cases}
  \end{equation*}
  On utilise la convention $Q_N = 0$, ainsi
  \begin{equation*}
    Q_{N-1}  = \E (\expp{-r(t_{N} - t_{N-1})}
    \max( \phi(S_{t_{N}}), Q_N) | S_{t_{N-1}}).
  \end{equation*}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{TV: étape de régression}

  De nouveau, on utilise une méthode de moindres carrés pour approcher $Q_j$.

  Soit $(g_l, l \geq 1)$ une base de fonctions telle que $\E(g_l(S_{t_j})
  g_{l^\prime}(S_{t_j})) < \infty$ pour tout $1 \leq j \leq d$. On cherche à
  approcher
  \begin{equation*}
    Q_j =  \E (\expp{-r(t_{j+1} - t_{j})}
    \max(\phi(S(t_{j+1}), Q_{j+1}) | S_{t_{j}})) = \psi_j(S_{t_{j}}).
  \end{equation*}
  par $\sum_{l=1}^k \alpha_l^j g_l(S_{t_j})$.

  $g_l$ peut dépendre de $j$. 

  $\alpha^j$ minimise
  \begin{equation*}
    \sum_{m=1}^M (Q_j^{(m)} - (\alpha^j \cdot g)(S_{t_j}^{(m)}) )^2.
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{TV: algorithme}
  \begin{enumerate}[1.]
  \item simuler $M$ trajectoires : $S_{t_N}^{(m)}$ pour $m=1 \dots M$.
  \item on pose $j=N-1$ et $Q_N^{(m)}=0$.
  \item \label{tv_loop} $Q_j{(m)} = \expp{-r(t_{j+1} - t_{j})}
    \max (\phi(S_{t_{j+1}}^{(m)}), Q_{j+1}^{(m)})$ pour $m=1 \dots M$.
  \item trouver $\alpha^j$ qui minimise
    \begin{equation*}
      \sum_{m=1}^M (Q_j^{(m)} - (\alpha^j \cdot g)(S_{t_j}^{(m)}) )^2.
    \end{equation*}
  \item on pose $Q_j^{(m)} = (\alpha \cdot g)(S_{t_j}^{(m)})$ pour $m=1 \dots M$.
  \item si $j>1$, on pose $j=j-1$ et on retourne en \ref{tv_loop}.
  \item si $j=1$, le prix est donné par
    \begin{equation*}
      \inv{M} \sum_{i=1}^M \expp{-r(t_{1} - t_{0})}
      \max (\phi(S_{t_0}), Q_{1}^{(m)}).
    \end{equation*}
  \end{enumerate}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{TV: comparaison avec LS}

  \begin{itemize}
  \item très proche de LS (en particulier de sa modification),
  \item LS n'utilise que les trajectoires dans la monnaie,
  \item TV utilise toutes les trajectoires,
  \item pratiquement, TV est moins performant que LS.
  \item on peut aussi utiliser des régresseurs normalisés.
  \end{itemize}

\end{frame}
%% ------------------------------------------------------------------------- %%
%% ------------------------------------------------------------------- FIN - %%

\subsection{Les Algorithmes de quantification}
\begin{frame}
  \frametitle{Plan}
  \tableofcontents[currentsection, currentsubsection]
\end{frame}
\subsubsection{Principes de la quantification}
\begin{frame}[allowframebreaks]
  \frametitle{Quantification de variables aléatoires}
  
  Soit $X$ une variable aléatoire dans $R^d$ et $n \in \N^\s$. On se donne
  \begin{itemize}
  \item un ensemble discret $\Gamma = \{y_1, \dots, y_n\} \subset \R^d$,
  \item une partition Borélienne $\ca=(A_i)_{i=1\dots n}$ de $\R^d$ telle que
    pour tout $i$, $y_i \in A_i$. $y_i$ est en général le centre de $A_i$ et on
    note $A_i = C_i(y)$.
  \end{itemize}

  Un $n-$quantificateur est une application $h_n : \R^d \longrightarrow $ telle
  que
  \begin{equation*}
    h_n(X) = \sum_{i=1}^n y_i \ind{X \in C_i(y)}.
  \end{equation*}

  Si $X \in \L^2$, un quantificateur $\L^2-$optimal est une application $h_n^\s$
  définie par la donnée de $\Gamma^\s$, et $\ca^\s$ qui réalise l'optimum dans
  le problème de minimisation
  \begin{equation*}
    \inf\left\{\E(\abs{X - h_n(X)}^2); \quad \{y_1, \dots, y_n\} \subset
      \R^d, \quad (A_i)_{i=1\dots n} \mbox{ partition de }\R^d \right\}. 
  \end{equation*}

  \begin{itemize}
  \item $\Gamma^\s$ est l'ensemble $\{y_1, \dots, y_n\}$ qui minimise $\inf
    \{\E(\min_{y\in \{y_1, \dots, y_n\}} \abs{X - y}^2); \quad \{y_1, \dots,
    y_n\} \}$;
  \item la partition $\ca^\s$ correspondante est l'ensemble des cellules de
    Voronoi associées à ces points $\{y_1, \dots, y_n\}$.
  \end{itemize}

  Cellule de Voronoi associé au point $y_i$
  \begin{equation*}
    Vor(y_i) = \{x \in \R^d : \forall y \in \Gamma \; d(x, y_i) \leq d(x, y)\}.
  \end{equation*}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{Quantification de processus}

  Soit $(X_k)_k$ un processus Markovien à temps discret simulable. On quantifie
  $X_k$ à chaque instant $k$.

  \begin{itemize}
  \item $n_k$ : taille de la grille de la quantification à l'instant $k$,
  \item $\Gamma_k = \{y_1^k, \dots, y^k_{n_k}\}$ la grille de quantif. à
    l'instant $k$,
  \item $\ca_k = (C_i(y))_{i=1\dots n}$ une partition Borélienne de $\R^d$,
  \item $\hat X_k$ le processus quantifié.
  \end{itemize}
  On définit le processus quantifié par
  \begin{equation}
    \label{eq:quantified_proc}
    \hat X_k := \sum_{i=1}^{n_k} y_i^k \ind{X_k \in C_i^k(y)}.
  \end{equation}
  $(\hat X_k)_k$ n'est plus un processus de Markov mais on peut calculer ses
  probabilités de transition
  \begin{equation}
    \label{eq:trnasition_quantif}
    p_{ij}^k := \P (\hat X_{k+1} = y_i^{k+1} | \hat X_{k} = y_j^{k}).
  \end{equation}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{Quantification et arrêt optimal}

  On rappelle que le prix de l'option américaine est
  donné par
  \begin{equation*}
    \begin{cases}
      U_N & = \expp{-r t_N} \phi(S_{t_N})\\
      U_k &= \max(\expp{-r t_k} \phi(S_{t_k}), \; \E (U_{k+1} | S_{t_{k}})),
      \quad 0\le k \le N-1. 
    \end{cases}
  \end{equation*}

  On quantifie le processus $(S_{t_k})_k$ et on considère
  \begin{equation}
    \label{eq:prog_dyn_quantif}
    \begin{cases}
      \hat U_N & = \expp{-r t_N} \phi(\hat S_{t_N})\\
      \hat U_k &= \max(\expp{-r t_k} \phi(\hat S_{t_k}), \; \E (\hat U_{k+1} |
      \hat S_{t_{k}})), \quad 0\le k \le N-1. 
    \end{cases}
  \end{equation}
  {\bf Problème :} Calcul de l'espérance conditionnelle.

  On définit la suite de fonction $\hat v_k$ par
  \begin{equation*}
    %% \label{eq:prog_dyn_quantif_fct}
    \begin{cases}
      \hat v_N(y_i^N) & = \expp{-r t_N} \phi(y_i^N) \quad i\in \{1, \dots, n_N\}\\
      \hat v_k(y_i^k) &= \max\left(\expp{-r t_k} \phi(y_i^k), \;
        \displaystyle  \sum_{j=1}^{n_{k+1}} p_{ij}^k \hat v_{k+1}(y_i^{k+1}) \right) 
      \quad
      {\small \begin{array}[c]{l}
          1 \leq i \leq n_k \\
          0\le k \le N-1
        \end{array}}.
    \end{cases}
  \end{equation*}
  
  {\bf Calcul de $p_{ij}^k$ :}
  \begin{eqnarray*}
    p_{ij}^k & = &\P (\hat S_{t_{k+1}} =  y_i^{k+1} | \hat S_{t_k} = y_j^{k}), \\
    & =& \frac{\P (S_{t_{k+1}} \in  A_i^{k+1} , S_{t_k} \in A_j^{k})}
    {\P(S_{t_k} \in A_j^{k})}. 
  \end{eqnarray*}
  On utilise une méthode de M.C. puisqu'on sait simuler le processus $X$.

  {\bf Pratiquement :} 
  \begin{enumerate}[1.]
  \item Simuler $(S^{(1)}, \dots, S^{(M)})$, $M$ trajectoires de $S$ aux
    instants $t_0, \dots, t_n$.
  \item Pour $k=1,\dots, n$,
    \begin{eqnarray*}
      p_{ij}^k & =& \frac{\sum_{m=1}^M \lind{S_{t_{k+1}}^{(m)} \in  A_i^{k+1}}
        \lind{S_{t_k}^{(m)} \in A_j^{k}}}
      {\sum_{m=1}^M  \lind{S_{t_k}^{(m)} \in A_j^{k}}}.
    \end{eqnarray*}
  \end{enumerate}

\end{frame}
%% ------------------------------------------------------------------------- %%

\subsubsection{Quantification aléatoire}
\begin{frame}[allowframebreaks]
  \frametitle{Quantification aléatoire (``self quantization'')}

  Supposons que pour tout instant $j$, $n_j = n$. On tire $n$ trajectoires
  $(S^{(1)}, \dots, S^{(N)})$, aux instants $t_0, \dots, t_N$ et on pose
  \begin{equation*}
    y_i^j := S^{(i)}_{t_j} \quad i=1,\dots, n \quad j=1,\dots,N.
  \end{equation*}

  On prend pour $A^j$ le diagramme de Voronoi associé aux points $\{y_i^j; \;
  i=1,\dots, n\}$.
  
\end{frame}
%% ------------------------------------------------------------------------- %%

\subsubsection{Quantification optimale}
\begin{frame}[allowframebreaks]
  \frametitle{Quantification optimale}
  
  Supposons que $n_j = n$. On cherche à minimiser la distorsion à tout instant $t_j$,
  \begin{equation*}
    D_{j} (y) := \E\left(  \min_{1 \leq k \leq n} \abs{S_{t_j} - y_k}^2 \right)
    = \E\left(  d_j(y, S_{t_j}) \right) .
  \end{equation*}
  avec
  \begin{equation*}
    d_j(y, \xi) = \min_{1 \leq k \leq n} \abs{\xi - y_k}^2.
  \end{equation*}
  $D_{j}$ est de classe $C^1$ en tout point $y \in {(\R^d)}^n$ et
  \begin{equation*}
    \nabla D_j(y) = \left( \E  \frac{\partial d_j}{\partial y_i} \right)_{i=1\dots n},
  \end{equation*}
  avec
  \begin{equation*}
    \frac{\partial d_j}{\partial y_i} (y, \xi)= (y_i - \xi) \lind{\xi \in A_i^j}.
  \end{equation*}

  On cherche $y^\s = (y_1^\s, \dots, y_n^\s) \in {\R^d}^n$ t.q. $\nabla
  D_j(y^\s) = 0$. On utilise un algorithme de gradient pour approcher
  $y^\s$. Soit $\xi_t$ une suite i.i.d. selon la loi de $S_{t_j}$ et $\gamma_t$
  une suite réelle positive décroissante vérifiant
  \begin{equation*}
    \sum_t \gamma_t = \infty \qquad \sum_t \gamma_t^2 < \infty.
  \end{equation*}
  Pour $Y_0 \in \R^{d \times n}$,
  \begin{equation*}
    Y_i^{t+1} = Y_i^t - \gamma_t (Y_i^t - \xi^{t+1}) \lind{ \xi^{t+1} \in A_i^j}.
  \end{equation*}
  Sous certaines hypothèses, $Y_i^t \xrightarrow[t \rightarrow
  \infty]{p.s.}y_i^\s$. On procède ainsi pour trouver les ensembles $\Gamma_j$
  à chaque pas de temps $t_0, \dots, t_N$.

  {\bf Remarque :} En pratique, on prend $\hat S_0 = S_0$ (supposé déterministe).
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{Quantification optimale: cas gaussien}

  Supposons que $S$ soit un M.B. Pour $y \in {(\R^d)}^n$.
  \begin{equation*}
    D_{t_j} (y) := \E\left(  \min_{1 \leq k \leq n} \abs{S_{t_j} - y_k}^2 \right)
    = \int_{\R^d} \min_{1 \leq k \leq n}
    \abs{u - y_k}^2 p(u, t_j) du.
  \end{equation*}
  Si $y^\s$ minimise $D_{1}$, alors grâce à la propriété d'échelle de la
  gaussienne $y^\s_j = \sqrt{t_j} y^\s$ minimise $D_{t_j}$.

  
  {\bf Approximation de $y^\s$.}
  
  Soit $Y \sim \cn(0, I_d)$ et $y^0 \in {(\R^d)}^n$. On pose
  \begin{equation*}
    y_k^{n+1} := \E \left( Y | Y  \in C_k( y^n)\right).
  \end{equation*}
  $(D_1(y^n))_n$ décroît et $y^n$ tend vers un minimum local de $D_1$ (global
  pour le cas $\cn(0, I_d)$).
\end{frame}
%% ------------------------------------------------------------------------- %%
%% ------------------------------------------------------------------- FIN - %%

\subsection{Algorithme de Broadie Glassermann}
\begin{frame}
  \frametitle{Plan}
  \tableofcontents[currentsection, currentsubsection]
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{BG: principe}

  \begin{itemize}
  \item discrétisation du sous-jacent à tout instant $t_j$ sur une grille
    aléatoire  $Y^j = \big\{Y_1^j, \dots, Y_n^j\big\} \subset {(\R^d)}^n$,
  \item problème de programmation dynamique est approché sur $Y^1, \dots, Y^n$
    en utilisant des poids $w \big(j, Y_k^j, Y_l^{j+1}\big)$ entre $Y_k^j$ et
    $Y_l^{j+1}$,
  \item les poids ne sont pas calculés en utilisant le noyau de transition du
    sous-jacent entre $t_j$ et $t_{j+1}$ mais par une méthode de fonctions
    d'importance.
  \end{itemize}
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{BG: Tirage de la grille}

  Soit $f(j, x, \cdot)$ la densité de $S_{t_{j+1}}$ sachant $S_{t_{j}}=x$ et
  $f(j, . )$ la densité de $S_{t_j}$ à $S_0$ fixé.
  \begin{enumerate}[1.]
  \item à la date $t_1$, on tire aléatoirement $Y^1_1, \dots, Y^1_n$
    i.i.d. selon la loi $f(1, \cdot)$.
  \item pour $j=2,\dots, N$, à la date $t_j$, $2$ stratégies
    \begin{enumerate}[a.]
    \item on tire $Y^j_1, \dots, Y^j_n$ selon $f(j, \cdot)$ \\
      {\bf Pb: } explosion de la variance de l'algorithme,
    \item autre stratégie, on tire $Y^j_1, \dots, Y^j_n$ selon la densité
      moyenne conditionnellement à $Y^{j-1}_1, \dots, Y^{j-1}_n$.
      \begin{equation*}
        \inv{n} \sum_{i=1}^n f(j-1, Y_i^{j-1}, \cdot).
      \end{equation*}
    \end{enumerate}
    on note $g(j, \cdot)$ la densité marginale de $Y^j_1, \dots, Y^j_n$.
  \end{enumerate}

\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{BG: calcul des poids}

  on chercher à approcher $\E\left( P(t_{j+1}, S_{t_{j+1}}) | S_{t_j} =
    Y_l^j\right)$ par
  \begin{equation*}
    \inv{n} \sum_{k=1}^{n} v_{j+1}(Y_k^{j+1})
    w \big(j, Y_l^j, Y_k^{j+1}\big).    
  \end{equation*}

  \begin{eqnarray*}
    \E\left( P(t_{j+1}, S_{t_{j+1}}) | S_{t_j} =
      Y_l^j\right) & = & \int P(t_{j+1}, u) f(j, Y_l^j, u) du,\\
    & = & \int  P(t_{j+1}, u) \frac{f(j, x, u)}{g(j+1, u)} g(j+1, u) du\\
    & = & \E_Y \left( P(t_{j+1}, Y)
      \frac{f(j, Y_l^j, Y)}{g(j+1, Y)} \right),
  \end{eqnarray*}
  avec $Y$ de loi $g(j+1, \cdot)$. Or $Y^j_1, \dots, Y^j_n$ est i.i.d. selon
  $g(j+1, \cdot)$.

  Ainsi on peut approcher $\E\left( P(t_{j+1}, S_{t_{j+1}}) | S_{t_j} =
    Y_l^j\right)$ par
  \begin{equation*}
    \inv{n} \sum_{k=1}^n P(t_{j+1}, Y_k^{j+1})
      \frac{f(j, Y^j_l, Y_l)}{g(j+1, Y_k^{j+1})}.
  \end{equation*}
  d' où
  \begin{equation*}
    w \big(j, Y_l^j, Y_k^{j+1}\big) := \frac{f(j, Y^j_l, Y_k^{j+1})}
    {g(j+1, Y_k^{j+1})} = \frac{f(j, Y^j_l, Y_k^{j+1})}
    { \inv{n} \sum_{i=1}^n f(j, Y_i^{j}, Y_k^{j+1} )}.
  \end{equation*}

  Comme $Y^1_1, \dots, Y^1_n$ est tiré selon $f(1, \cdot)$, $w(0, S_0, \cdot)=1$.
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{BG: programmation dynamique}

  Soit la suite de fonctions $v_j$
  \begin{equation*}
    \begin{cases}
      v_N(Y_l^N) & = \expp{- r t_N} \phi(Y_i^N) \quad $l=1, \dots, n$,\\
      v_k(Y_l^j) &= \max\left(\expp{-r t_j} \phi(Y_l^j), \;
        \displaystyle  \inv{n} \sum_{k=1}^{n} v_{j+1}(Y_k^{j+1})
        w \big(j, Y_l^j, Y_k^{j+1}\big) \right) \\
      & \quad l=1,\dots, n \quad k=1,\dots, N-1.
    \end{cases}
  \end{equation*}
  Le prix est donné par
  \begin{equation*}
    \max\left( \phi(S_0), \inv{n} \sum_{k=1}^{n} v_{1}(Y_k^{1})
        w \big(0, Y_{S_0}^0, Y_k^{1}\big) \right).
  \end{equation*}
\end{frame}
%% ------------------------------------------------------------------------- %%
%% ------------------------------------------------------------------- FIN - %%

\subsection{Algorithme de Barraquand Martineau}
\begin{frame}
  \frametitle{Plan}
  \tableofcontents[currentsection, currentsubsection]
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}
  \frametitle{BM : Principe}

  Supposons qu'à l'instant $t$, on ne connaisse que $\{\phi(S_u) ; u \leq t\}$
  et pas $\{S_u ; u \leq t\}$, alors on ne peut optimiser $\E (\expp{-r \tau}
  \phi(S_\tau))$ que pour $\tau$ t.a. pour la filtration $\cg$ générée par
  $\{\phi(S_u) ; u \leq t\}$.

  On rappelle le problème de programmation dynamique
  \begin{equation*}
    \begin{cases}
      U_N & = \expp{-r t_N} \phi(S_{t_N})\\
      U_n &= \max(\expp{-r t_n} \phi(S_{t_n}), \; \E (U_{n+1} | S_{t_{n}})),
      \quad 0\le n \le N-1. 
    \end{cases}
  \end{equation*}
  que l'on approche par
  \begin{equation*}
    \begin{cases}
      U_N & = \expp{-r t_N} \phi(S_{t_N})\\
      U_n &= \max(\expp{-r t_n} \phi(S_{t_n}), \; \E (U_{n+1} | \cg_{t_{n}})),
      \quad 0\le n \le N-1. 
    \end{cases}
  \end{equation*}
  Numériquement, on ne sait pas estimer $\E (U_{n+1} | \cg_{t_{n}})$, on la
  remplace par $\E (U_{n+1} | \phi(S_{t_{n}}))$.

  \then\ Problème unidimensionnel : on utilise une méthode de
  quantification pour approcher $\E (U_{n+1} | \phi(S_{t_{n}}))$.
\end{frame}
%% ------------------------------------------------------------------------- %%

\begin{frame}[allowframebreaks]
  \frametitle{BM: quantification du payoff}

  Pour $j=1, \dots, N$, on pose $\{z_{1}^j <  \dots < z_{n_j}^j\} \subset \R$
  avec $z_{1}^j:= -\infty$ et  $z_{n_j}^j:= -\infty$. On définit les
  quantificateurs
  \begin{equation}
    \label{eq:BM_quantifiers}
    y_k^j := \E\left ( \phi(S_{t_{j}}) \; \big | \;
      \phi(S_{t_{j}}) \in \left[z_k^j, z_{k+1}^j\right] \right).
  \end{equation}
  Puisque $S_O$ est déterministe, on prend $y^0 := \phi(S_{0})$.
  first ref : \ref{eq:BM_quantifiers}
  
  Soit $P_j(x, du)$ le noyau de transition de $\phi(S_{t_{j}})$ (loi de
  $\phi(S_{t_{j+1}})$ sachant $\phi(S_{t_{j}})=x$).

  On introduit
  \begin{eqnarray}
    \label{eq:BM_quantif_kernel}
    p^j_{kl} & := & \P\left( \phi(S_{t_{j+1}}) \in \left[z_k^{j+1},
        z_{k+1}^{j+1}\right] \Big | \phi(S_{t_{j}}) \in \left[z_l^{j},
        z_{l+1}^{j}\right] \right)\\
    &= &\frac
    {\E\left( \lind{\phi(S_{t_{j+1}}) \in \left[z_k^{j+1},z_{k+1}^{j+1}\right]}
        P_j\left(\phi(S_{t_{j}}), \left[z_l^{j},z_{l+1}^{j}\right]\right)
      \right)}
    {\E\left( \lind{\phi(S_{t_{j+1}}) \in \left[z_k^{j+1},z_{k+1}^{j+1}\right]}
      \right)}.
  \end{eqnarray}
  second ref : \ref{eq:BM_quantifiers}
  blabla \ref{eq:prix_amer} pooo \ref{eq:prog_dyn}
  
  En posant $v_j (x) = \E\left( U_j | \phi(S_{t_j}) = x \right)$, le problème de
  programmation dynamique se réécrit
  \begin{equation*}
    \begin{cases}
      v_N(y_i^N) & = \expp{-r t_N} y_i^N, \quad i\in \{1, \dots, n_N\}\\
      v_k(y_i^k) &= \max\left(\expp{-r t_k} y_i^k, \;
        \displaystyle  \sum_{j=1}^{n_{k+1}} p_{ij}^k v_{k+1}(y_i^{k+1}) \right),
      \quad
      {\small \begin{array}[c]{l}
          1 \leq i \leq n_k \\
          0\le k \le N-1
        \end{array}}.
    \end{cases}
  \end{equation*}

  Le prix est donné par $v_0 (s_{t_0})$.
  
  {\bf En pratique : } pour $\left[z_k^j, z_{k+1}^j\right]$, on prend la cellule
  de Voronoi $C_k(y^j)$. En dimension $1$, pas de problème d'optimisation à
  résoudre.
  \begin{equation*}
    C_k (y^j) = \Big[ \frac{y_{k-1}^j +  y_{k}^j}{2},
    \frac{y_{k}^j+ y_{k+1}^j}{2} \Big] := \left[z_k^j, z_{k+1}^j\right].
  \end{equation*}

  $y_k^j$ \eqref{eq:BM_quantifiers} est approché par
  \begin{equation*}
    \inv{\abs{E_k^j}} \sum_{m \in E_k^j} \phi(S_{t_j}^{(m)}),
  \end{equation*}
  où $S_{t_j}^{(1)}, \dots, S_{t_j}^{(M)}$ sont $M$ tirages i.i.d de $S_{t_j}$
  et $E_j^k := \big\{m \;; \phi(S_{t_j}^{(m)}) \in \big[z_k^j, z_{k+1}^j\big]
  \big\}$.

  $p^j_{kl}$ \eqref{eq:BM_quantif_kernel} est approché par
  \begin{equation*}
    \frac{\abs{ E_k^j \cap E_l^{j+1}}}{\abs{E_k^j}}.
  \end{equation*}
\end{frame}
%% ------------------------------------------------------------------------- %%
%% ------------------------------------------------------------------- FIN - %%

\end{document}
