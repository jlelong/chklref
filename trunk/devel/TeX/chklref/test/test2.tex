\documentclass[a4paper,11pt,twoside]{article}

\usepackage{a4wide}
\usepackage{latexsym}
\usepackage[francais]{babel}
\usepackage{amssymb, amsmath, amsthm}
\usepackage[latin1]{inputenc}
\usepackage{enumitem}
%%\usepackage[bookmarks=true,  colorlinks=true,  linkcolor=blue, hypertexnames=false]{hyperref}
%%\usepackage[notcite,notref]{showkeys}
%%\usepackage{refcheck}

\makeatletter


\makeatother

%e --------------------------------------------
\hbadness=10000
\emergencystretch=\hsize
\tolerance=9999
%% \textheight=9.0in
%% --------------------------------------------
\parindent=0pt
%% math envs
\theoremstyle{plain}
\newtheorem{thm}{Théorème}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemme}
\newtheorem*{remark}{Remarque}
\newtheorem{cor}{Corollary}
\newtheorem*{rem}{Remarque}
\newtheorem*{algo}{Algorithme}
\theoremstyle{definition}
\newtheorem{exo}{Exercice}
\renewcommand{\qedsymbol}{$\blacksquare$}


%%%%%% new macros

\def\ca{{\mathcal A}}
\def\cb{{\mathcal B}}
\def\cc{{\mathcal C}}
\def\cd{{\mathcal D}}
\def\ce{{\mathcal E}}
\def\cf{{\mathcal F}}
\def\cg{{\mathcal G}}
\def\ch{{\mathcal H}}
\def\ci{{\mathcal I}}
\def\cj{{\mathcal J}}
\def\ck{{\mathcal K}}
\def\cl{{\mathcal L}}
\def\cn{{\mathcal N}}
\def\cm{{\mathcal M}}
\def\co{{\mathcal O}}
\def\cp{{\mathcal P}}
\def\cs{{\mathcal S}}
\def\cu{{\mathcal U}}
\def\cv{{\mathcal V}}
\def\cw{{\mathcal W}}
\def\cx{{\mathcal X}}
\def\C{{\mathbb C}}
\def\D{{\mathbb D}}
\def\E{{\mathbb E}}
\def\L{{\mathbb L}}
\def\N{{\mathbb N}}
\def\P{{\mathbb P}}
\def\Q{{\mathbb Q}}
\def\R{{\mathbb R}}
\def\S{\Sigma}
\def\Z{{\mathbb Z}}
\def\s{\star}
\def\rP{{\rm P}}
\def\rQ{{\rm Q}}
\def\rpartial{{\rm d}}
\def\ind#1{{\bf 1}_{\left\{ #1 \right\}}}
\def\id{{\mathcal I}}
\def\abs#1{\left|#1\right|}
\def\norm#1{\mathop{\left\| #1 \right\|}\nolimits}
\def\supp{{\rm supp}\;}
\def\Det{{\rm det}\;}
\def\Card{{\rm Card}\;}
\def\inv#1{\mathop{\frac{1}{ #1}}\nolimits}
\def\expp#1{\mathop {\mathrm{e}^{ #1}}}
\def\interior#1{\mathop {\mathrm{int}(#1)}}
\def\dpart#1#2{\frac{\partial #1}{\partial #2}}
\def\dpartsec#1#2{\frac{\partial^2 #1}{\partial {#2}^2}}
\def\dpart#1#2{\frac{\partial #1}{\partial #2}}
\def\d#1#2{\frac{d #1}{d #2}}
\def\tr#1{{#1}^{{\scriptstyle\mathrm T}}}

%% proba et espérances
\def\proba#1{\P\left(#1 \right)}
\def\esp#1{\E\left(#1 \right)}
\def\espbracket#1{\E\left[#1 \right]}
\def\espcond#1#2{\E\left(#1 \left| #2 \right. \right)}
\def\espbracketcond#1#2{\E\left[#1 \left| #2 \right. \right]}
\def\Cov{\mathop{\rm Cov}\nolimits}
\def\Var{\mathop{\rm Var}\nolimits}
\def\Covop#1{\mathop{\rm Cov}\nolimits\left(#1\right)}
\def\Varop#1{\mathop{\rm Var}\nolimits\left(#1\right)}

%% a few abbrevs
\def\BS{Black Scholes}


\title{Projets du cours MAE52}
\date{\today}
\author{Céline Labart et J\'er\^ome Lelong}


\begin{document}
\maketitle

On rappelle que dans le modèle de \BS\ l'évolution de l'actif $(S_t)_{0\le t \le
  T}$ est modélisée par la dynamique
\begin{align}
  \label{alig}
  dS_t=S_t(rdt+\sigma dW_t), \quad S_0=x
\end{align}
où $\sigma>0$ représente la volatilité du modèle et $r>0$ représente le taux
d'intérêt sans risque.


\section{Méthodes d'arbre pour les options américaines}

On proposer de calculer le prix du put américain dans un modèle d'arbre.
\begin{itemize}
\item Implémenter la résolution de l'équation de programmation dynamique dans un
  modèle d'arbre.
\item Comparer les résultats pour les modèles de Cox Ross Rubinstein et de
  Kamrad Ritchken
\item Etudier la vitesse de convergence quand le pas de l'arbre tend vers $0$.
\end{itemize}


\section{Inéquation aux dérivées partielles pour les options américaines}


On se propose de calculer le prix du put américain dans le modèle de Black
Scholes en résolvant l'inéquation aux dérivées partielles satisfaites par sa
fonction prix.

\subsection{Formulation du problème}


On considère l'opérateur elliptique $A$ défini par
\begin{equation*}
  \cl = \frac{\sigma^2}{2} \frac{\partial^2}{\partial x^2} + \left(r -
    \frac{\sigma^2}{2}\right) \frac{\partial}{\partial x} -r
\end{equation*}
où $r$ et $\sigma$ sont deux constantes réelles.
On se donne une fonction $f : \R \longrightarrow \R_+$, un ouvert $\co_l = ]-l, l[$
et on cherche à résoudre le problème suivant
\begin{equation}
  \label{eq:ineq_diff}
  \tag{$E$}
  \left\{
    \begin{array}{l}
      \dpart{v}{t}(t,x) + \cl v(t,x) \leq 0 \quad \mbox{dans $[0,T] \times \co_l$}\\
      v(t,x) \geq f(x)\\
      (v(t,x) - f(x)) \left(\dpart{v}{t}(t,x) + \cl v(t,x)\right) = 0 \quad \mbox{dans $[0,T]
        \times \co_l$}\\ 
      v(T,x) = f(x)\\
      \dpart{v}{x}(t, \pm l) = 0.
    \end{array}
  \right.
\end{equation}

Soit $v(t, y)$ le prix à l'instant $t$ du put américain dans le modèle de
Black Scholes si le sous-jacent vaut $\expp{y}$. La fonction $v$ est solution du
système~\ref{eq:ineq_diff} avec $l=\infty$ et $f(x) = (K - \expp{x})_+$.

\subsection{Méthode de résolution}
\subsubsection{discrétisation du système d'inéquations}

Nous allons maintenant voir comment résoudre le système~(\ref{eq:ineq_diff}) par une
méthode numérique. On se propose d'utiliser une méthode de différences finies pour
discrétiser le système à la fois en temps et en espace.

Soit $N \in \N^*$, on note $h = \frac{2l}{N+1}$ et $x_i = -l + ih$ pour $0 \leq i
\leq N+1$. On définit le vecteur $f_h$ par $f_h^i=f(x_i)$.

Pour toute fonction $u: \co_l \longrightarrow \R$, on adopte la notation $u_h =
{(u_h^i)}_{1 \leq i \leq N} = {(u(x_i))}_{1 \leq i \leq N}$. On considère la
discrétisation de l'opérateur $\cl$ suivante
\begin{equation*}
  (\cl_h u_h)_i = \frac{\sigma^2}{2h^2} (u_h^{i+1} - 2 u_h^i + u_h^{i-1}) + \left(r -
    \frac{\sigma^2}{2}\right) \frac{1}{2h}  (u_h^{i+1} - u_h^{i-1}) -r u_h^i
\end{equation*}
L'opérateur $\cl_h$ peut donc être représenté par la matrice tridiagonale suivant
\[
\cl_h = 
\begin{pmatrix}
  \beta & \gamma & 0 & \dots & 0 & 0 \\
  \alpha & \beta & \gamma & 0 & \dots & 0 \\
  0 & \alpha & \beta & \gamma & \dots & 0 \\
  0 & \vdots & \ddots & \ddots & \ddots & \vdots \\
  0 & 0 & \dots & \alpha & \beta & \gamma \\
  0 & 0 & 0 & \dots & \alpha & \beta 
\end{pmatrix}
\]
avec
\[
\begin{cases}
  \alpha  = & \frac{\sigma^2}{2 h^2} - \frac{1}{2h} \left(r -
    \frac{\sigma^2}{2} \right), \\
  \beta  = & -\frac{\sigma^2}{h^2} - r, \\
  \gamma  = & \frac{\sigma^2}{2 h^2} + \frac{1}{2h} \left(r -
    \frac{\sigma^2}{2}\right).
\end{cases}
\]
Une fois cette discrétisation en espace effectuée, on se ramène à une équation
différentielle ordinaire ne portant que sur le temps
\begin{equation}
  \label{eq:ineq_diff_h}\tag{$E_h$}
  \begin{cases}
    \displaystyle \d{u_h}{t}(t) + \cl_h u_h(t) \leq 0 \quad \forall t \in
    [0,T],\\
    u_h(t) \geq f_h\\
    (u_h(t) - f) \left(\d{u_h}{t}(t) + \cl_h u_h(t)\right) = 0 \quad \mbox{dans
      $[0,T]$}\\  
    u_h(T) = f_h\\
    \d{v}{x}(t, \pm l) = 0.
  \end{cases}
\end{equation}
Si $x$ et $y$ sont deux vecteurs de $\R^d$, on note $x \leq y$ pour $x_i \leq y_i
\; \forall 1 \leq i \leq d$. Il ne reste plus alors qu'à discrétiser
l'équation~(\ref{eq:ineq_diff_h}) grâce à des $\theta-$schémas. On note $k =
\frac{T}{M}$ le pas de discrétisation en temps.  On approche alors la solution $u_h$
de~(\ref{eq:ineq_diff_h}) à l'instant $mk$ par $u_{h,k}^m$ défini par
\begin{equation}
  \label{eq:sys_discre_k_h}\tag{$E_{h,k}$}
  \begin{cases}
    u_{h,k}^M = f_h, \\
    \mbox{Et pour $0 \leq m \leq M-1$}\\ 
    u_{h,k}^m \geq f_h \\ 
    u_{h,k}^{m+1} - u_{h,k}^m + k (\theta \cl_h u_{h,k}^m + (1 -
    \theta) \cl_h u_{h,k}^{m+1})   \leq 0 \\
    \left(u_{h,k}^{m+1} - u_{h,k}^m + k (\theta \cl_h u_{h,k}^m + (1 -
      \theta) \cl_h u_{h,k}^{m+1}) , u_{h,k}^m - f_h\right) = 0
  \end{cases}
\end{equation}
où $(x,y)$ est le produit scalaire de $\R^N$.

En introduisant les notations matricielles suivantes
\begin{equation*}
  \begin{cases}
    T = & I - k\theta \cl_h\\
    G  = & \left(I + k(1-\theta) \cl_h\right) u_{h,k}^{m+1}\\
    M  = & \left(I + k(1-\theta) \cl_h\right)
  \end{cases}
\end{equation*}
le système~(\ref{eq:sys_discre_k_h}) se réécrit
\begin{equation*}
  \begin{cases}
    T u_{h,k}^m - M u_{h,k}^{m+1} & \geq  0 \\
    u_{h,k}^m - u_{h,k}^M & \geq  0\\
    \tr{(T u_{h,k}^m  - M u_{h,k}^{m+1})} (u_{h,k}^m - u_{h,k}^M) & = 0.
  \end{cases}
\end{equation*}
La matrice $T$ est tridiagonale
\[
T = 
\begin{pmatrix}
  a + b & c & 0 & \dots & 0 & 0 \\
  a & b & c & 0 & \dots & 0 \\
  0 & a & b & c & \dots & 0 \\
  0 & \vdots & \ddots & \ddots & \ddots & \vdots \\
  0 & 0 & \dots & a & b & c \\
  0 & 0 & 0 & \dots & a & b+c 
\end{pmatrix}
\]
avec 
\[
\begin{pmatrix}
  a & = & \theta k \left( -\frac{\sigma^2}{2 h^2} + \frac{1}{2h} \left(r -
      \frac{\sigma^2}{2} \right) \right) \\
  b & = & 1 + \theta k \left(\frac{\sigma^2}{h^2} + r\right) \\
  c & = & - \theta k \left( \frac{\sigma^2}{2 h^2} + \frac{1}{2h} \left(r -
      \frac{\sigma^2}{2} \right) \right).
\end{pmatrix}
\]
A chaque pas $m$ de $M-1$ à $1$, il s'agit de résoudre un système d'inéquations linéaires


\subsubsection{algorithme de résolution}

Il existe plusieurs algorithmes permettant de résoudre un tel système d'inéquations
linéaires. On propose ici d'utiliser la méthode dite par troncature.
\begin{algo}
  Pour $m$ variant de $M-1$ à $1$, on résout 
  \begin{equation*}
    T x = M u_{h,k}^{m+1},
  \end{equation*}
  puis on pose
  \begin{equation*}
    u_{h,k}^m = \max(x, f_h).
  \end{equation*}
\end{algo}
Pour assurer la convergence de l'algorithme ci-dessus, on veillera à ce que les paramètres
vérifient les conditions suivantes
\begin{equation*}
  \abs{r -\frac{\sigma^2}{2}} \leq \frac{\sigma^2}{h} \quad \mbox{et} \quad
  \frac{k}{2h} \abs{r -\frac{\sigma^2}{2}} < 1.
\end{equation*}
Ces conditions assurent que la matrice $T$ est coercive (c.à.d $\tr{x}Tx \leq c
\tr{x}x$ avec $c>0$).

\subsection{Travail demandé}

\begin{itemize}
\item Résoudre le système~\eqref{eq:ineq_diff} par la méthode détaillée
  ci-dessus.
\item Dans la résolution du système linéaire, on s''efforcera de tirer profit
  dans la structure tribande de la matrice en utilisant une décomposition de
  type $Q = LU$, avec $L$ triangulaire inférieure et $U$ triangulaire. Ainsi le
  système $Qx = b$ se résout en 2 étapes $Ly=b$ puis $Ux =y$.
\item On s'intéressa aux cas $\theta=0$, $\theta=1/2$ et $\theta=1$. Comparer la
  convergence pour ces différentes valeurs.
\end{itemize}

\section{Méthode de Monte Carlo pour les options américaines}

On se propose de calculer le prix du put américain dans le modèle de Black
Scholes par une méthode de Monte Carlo. 

\subsubsection*{Travail demandé}
\begin{itemize}
\item Il s'agit d'implémenter l'algorithme de
  Longstaff et Schwartz en dimension $1$.

  Pour la partie régression de l'algorithme, on pourra par exemple utiliser la
  base canonique des polynômes de degré inférieur à $n$ $(x^d, 0 \le d \le n)$. On
  pourra également ajouter à cette famille libre la fonction de payoff elle-même.

\item Etudier la convergence en fonction du nombre de pas de temps, du nombre de
  fonctions de base et de nombre de tirages Monte Carlo.
\end{itemize}

pipo

\Input{test21.tex}

\end{document}

